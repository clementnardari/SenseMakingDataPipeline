{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "160d3e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task Functions (used to facilitate tasks)\n",
    "import urllib. request\n",
    "import time\n",
    "import glob, os\n",
    "import json\n",
    "\n",
    "#create a data folder to store all the raw data\n",
    "if not os.path.exists('data'):\n",
    "    os.mkdir('data')\n",
    "    print(\"Directory data created\")   \n",
    "\n",
    "# pull course catalog pages\n",
    "def catalog():\n",
    "    #list of urls from the MIT course catalog\n",
    "    file = open('./00_urls.txt')\n",
    "    lines = file.readlines()\n",
    "    url_list = [line.rstrip() for line in lines]\n",
    "    \n",
    "    #urls_list = open('./00_urls.txt').readlines()\n",
    "    #print(url_list)\n",
    "    \n",
    "    def pull(url):\n",
    "        response = urllib.request.urlopen(url).read()\n",
    "        data = response.decode('utf-8')\n",
    "        return data\n",
    "    def store(data,file):\n",
    "        # Create path:\n",
    "        path = os.path.join('./data', file)\n",
    "\n",
    "        # Create a file a file\n",
    "        page = os.open(path, os.O_RDWR|os.O_CREAT )\n",
    "\n",
    "        # Write tp the file\n",
    "        os.write(page, data.encode())\n",
    "\n",
    "        # Close the file\n",
    "        os.close(page)\n",
    "\n",
    "        print('wrote file: ' + file)\n",
    "    \n",
    "    def combine():\n",
    "\n",
    "        if os.path.exists('combo.txt'):\n",
    "            os.remove('combo.txt')\n",
    "            print(\"combo.txt removed\") \n",
    "        page = os.open('combo.txt', os.O_RDWR|os.O_CREAT )\n",
    "        os.close(page)\n",
    "        print(\"combo.txt created\") \n",
    "\n",
    "        with open('combo.txt','w') as outfile:\n",
    "            for file in glob.glob(\"./data/*.html\"):\n",
    "                with open(file) as infile:\n",
    "                    outfile.write(infile.read())\n",
    "\n",
    "    #loop through all urls\n",
    "    for url in url_list:\n",
    "        try:\n",
    "            #get page name\n",
    "            file=url.split(\"/\")[-1]\n",
    "            data=pull(url)\n",
    "            store(data,file)        \n",
    "            print(f'Pulled: {url}')\n",
    "            print('--- waiting ---')\n",
    "            time.sleep(15)\n",
    "        except:\n",
    "            print(f'Not found: {url}')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18f8000e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine():\n",
    "        \n",
    "    if os.path.exists('combo.txt'):\n",
    "        os.remove('combo.txt')\n",
    "        print(\"combo.txt removed\") \n",
    "    page = os.open('combo.txt', os.O_RDWR|os.O_CREAT )\n",
    "    os.close(page)\n",
    "    print(\"combo.txt created\") \n",
    "        \n",
    "    with open('combo.txt','w') as outfile:\n",
    "        for file in glob.glob(\"./data/*.html\"):\n",
    "            with open(file) as infile:\n",
    "                outfile.write(infile.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc3599e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combo.txt removed\n",
      "combo.txt created\n"
     ]
    }
   ],
   "source": [
    "combine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f319a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = os.open('./00_urls.txt', os.O_RDONLY)\n",
    "# Close the file\n",
    "#    os.close(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0d5e2a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('./00_urls.txt')\n",
    "url_list = file.readlines()\n",
    "lines = [line.rstrip() for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "94ff4b2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'readlines' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [46]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Open a file\u001b[39;00m\n\u001b[0;32m      2\u001b[0m fd \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mopen( \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./00_urls.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, os\u001b[38;5;241m.\u001b[39mO_RDWR\u001b[38;5;241m|\u001b[39mos\u001b[38;5;241m.\u001b[39mO_CREAT )\n\u001b[1;32m----> 3\u001b[0m lines \u001b[38;5;241m=\u001b[39m \u001b[43mreadlines\u001b[49m(fd)\n\u001b[0;32m      4\u001b[0m lines \u001b[38;5;241m=\u001b[39m [line\u001b[38;5;241m.\u001b[39mrstrip() \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'readlines' is not defined"
     ]
    }
   ],
   "source": [
    "# Open a file\n",
    "fd = os.open( './00_urls.txt', os.O_RDWR|os.O_CREAT )\n",
    "lines = readlines(fd)\n",
    "lines = [line.rstrip() for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fbb5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = url.rfind('/') + 1\n",
    "#call pull function\n",
    "\n",
    "file = url[index:]\n",
    "#call store function\n",
    "\n",
    "print('pulled: ' + file)\n",
    "print('--- waiting ---')\n",
    "time.sleep(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8b0a52ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine():\n",
    "    with open('combo.txt','w') as outfile:\n",
    "           for file in glob.glob(\"./data/*.html\"):\n",
    "                with open(file) as infile:\n",
    "                    outfile.write(infile.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "046af1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "def store_json(data,file):\n",
    "       with open(file, 'w', encoding='utf-8') as f:\n",
    "           json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "           print('wrote file: ' + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f87efaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def titles():\n",
    "    from bs4 import BeautifulSoup\n",
    "    def store_json(data,file):\n",
    "           with open(file, 'w', encoding='utf-8') as f:\n",
    "                json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "                print('wrote file: ' + file)\n",
    "\n",
    "    #Open and read the large html file generated by combine()\n",
    "    with open('combo.txt') as file:\n",
    "        html=file.read()\n",
    "\n",
    "    #the following replaces new line and carriage return char\n",
    "    html = html.replace('\\n', ' ').replace('\\r', '')\n",
    "    #the following create an html parser\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    results = soup.find_all('h3')\n",
    "    titles = []\n",
    "\n",
    "    # tag inner text\n",
    "    for item in results:\n",
    "        titles.append(item.text)\n",
    "    store_json(titles, 'titles.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "855fe819",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('combo.txt') as file:\n",
    "    file=file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2888e943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote file: titles.json\n"
     ]
    }
   ],
   "source": [
    "titles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b00cff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean():\n",
    "    #complete helper function definition below\n",
    "    def store_json(data,file):\n",
    "           with open(file, 'w', encoding='utf-8') as f:\n",
    "                json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "                print('wrote file: ' + file)\n",
    "                \n",
    "    with open('titles.json') as file:\n",
    "        titles = json.load(file)\n",
    "        # remove punctuation/numbers\n",
    "        for index, title in enumerate(titles):\n",
    "            punctuation= '''!()-[]{};:'\"\\,<>./?@#$%^&*_~1234567890'''\n",
    "            translationTable= str.maketrans(\"\",\"\",punctuation)\n",
    "            clean = title.translate(translationTable)\n",
    "            titles[index] = clean\n",
    "\n",
    "        # remove one character words\n",
    "        for index, title in enumerate(titles):\n",
    "            clean = ' '.join( [word for word in title.split() if len(word)>1] )\n",
    "            titles[index] = clean\n",
    "\n",
    "        store_json(titles, 'titles_clean.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8424b00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote file: titles_clean.json\n"
     ]
    }
   ],
   "source": [
    "clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f1432ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words():\n",
    "    from collections import Counter\n",
    "    def store_json(data,file):\n",
    "           with open(file, 'w', encoding='utf-8') as f:\n",
    "                json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "                print('wrote file: ' + file)\n",
    "    with open('titles_clean.json') as file:\n",
    "        titles = json.load(file)\n",
    "        words = []\n",
    "\n",
    "        # extract words and flatten\n",
    "        for title in titles:\n",
    "            words.extend(title.split())\n",
    "\n",
    "        # count word frequency\n",
    "        counts = Counter(words)\n",
    "        store_json(counts, 'words.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01338574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote file: words.json\n"
     ]
    }
   ],
   "source": [
    "count_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f9df25",
   "metadata": {},
   "outputs": [],
   "source": [
    "with DAG(\n",
    "    \"assignment\",\n",
    "    start_date=days_ago(1),\n",
    "    schedule_interval=\"@daily\",catchup=False,\n",
    ") as dag:\n",
    "\n",
    "    # INSTALL BS4 BY HAND THEN CALL FUNCTION\n",
    "\n",
    "    # ts are tasks\n",
    "    t0 = BashOperator(\n",
    "        task_id='task_zero',\n",
    "        bash_command='pip install beautifulsoup4',\n",
    "        retries=2\n",
    "    )\n",
    "    t1 = PythonOperator(\n",
    "        task_id='task_one',\n",
    "        depends_on_past=False,\n",
    "        python_callable=catalog\n",
    "    )\n",
    "    t2 = PythonOperator(\n",
    "        task_id='task_two',\n",
    "        depends_on_past=False,\n",
    "        python_callable=combine\n",
    "    )\n",
    "    t3 = PythonOperator(\n",
    "        task_id='task_three',\n",
    "        depends_on_past=False,\n",
    "        python_callable=titles\n",
    "    )\n",
    "    t4 = PythonOperator(\n",
    "        task_id='task_four',\n",
    "        depends_on_past=False,\n",
    "        python_callable=clean\n",
    "    )\n",
    "    t5 = PythonOperator(\n",
    "        task_id='task_five',\n",
    "        depends_on_past=False,\n",
    "        python_callable=count_words\n",
    "    )\n",
    "    #define tasks from t2 to t5 below\n",
    "\n",
    "\n",
    "    t0>>t1>>t2>>t3>>t4>>t5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
